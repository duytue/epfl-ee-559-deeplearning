{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.1416) tensor(1.00000e-08 *\n",
      "       8.7423) tensor(0.1836)\n",
      "tensor(-3.0781) tensor(1.00000e-02 *\n",
      "       -6.3424) tensor(1.00000e-02 *\n",
      "       6.7733)\n",
      "tensor(-3.0147) tensor(-0.1266) tensor(1.00000e-02 *\n",
      "       -4.1222)\n",
      "tensor(-2.9512) tensor(-0.1893) tensor(-0.1435)\n",
      "tensor(-2.8877) tensor(-0.2511) tensor(-0.2391)\n",
      "tensor(-2.8243) tensor(-0.3120) tensor(-0.3283)\n",
      "tensor(-2.7608) tensor(-0.3717) tensor(-0.4112)\n",
      "tensor(-2.6973) tensor(-0.4298) tensor(-0.4880)\n",
      "tensor(-2.6339) tensor(-0.4862) tensor(-0.5587)\n",
      "tensor(-2.5704) tensor(-0.5406) tensor(-0.6236)\n",
      "tensor(-2.5069) tensor(-0.5929) tensor(-0.6827)\n",
      "tensor(-2.4435) tensor(-0.6428) tensor(-0.7363)\n",
      "tensor(-2.3800) tensor(-0.6901) tensor(-0.7844)\n",
      "tensor(-2.3165) tensor(-0.7346) tensor(-0.8272)\n",
      "tensor(-2.2531) tensor(-0.7761) tensor(-0.8648)\n",
      "tensor(-2.1896) tensor(-0.8146) tensor(-0.8974)\n",
      "tensor(-2.1261) tensor(-0.8497) tensor(-0.9251)\n",
      "tensor(-2.0627) tensor(-0.8815) tensor(-0.9481)\n",
      "tensor(-1.9992) tensor(-0.9096) tensor(-0.9665)\n",
      "tensor(-1.9357) tensor(-0.9341) tensor(-0.9804)\n",
      "tensor(-1.8723) tensor(-0.9549) tensor(-0.9900)\n",
      "tensor(-1.8088) tensor(-0.9718) tensor(-0.9955)\n",
      "tensor(-1.7453) tensor(-0.9848) tensor(-0.9968)\n",
      "tensor(-1.6819) tensor(-0.9938) tensor(-0.9944)\n",
      "tensor(-1.6184) tensor(-0.9989) tensor(-0.9881)\n",
      "tensor(-1.5549) tensor(-0.9999) tensor(-0.9783)\n",
      "tensor(-1.4915) tensor(-0.9969) tensor(-0.9649)\n",
      "tensor(-1.4280) tensor(-0.9898) tensor(-0.9483)\n",
      "tensor(-1.3645) tensor(-0.9788) tensor(-0.9285)\n",
      "tensor(-1.3011) tensor(-0.9638) tensor(-0.9056)\n",
      "tensor(-1.2376) tensor(-0.9450) tensor(-0.8798)\n",
      "tensor(-1.1741) tensor(-0.9224) tensor(-0.8513)\n",
      "tensor(-1.1107) tensor(-0.8960) tensor(-0.8201)\n",
      "tensor(-1.0472) tensor(-0.8660) tensor(-0.7865)\n",
      "tensor(-0.9837) tensor(-0.8326) tensor(-0.7505)\n",
      "tensor(-0.9203) tensor(-0.7958) tensor(-0.7124)\n",
      "tensor(-0.8568) tensor(-0.7557) tensor(-0.6721)\n",
      "tensor(-0.7933) tensor(-0.7127) tensor(-0.6300)\n",
      "tensor(-0.7299) tensor(-0.6668) tensor(-0.5861)\n",
      "tensor(-0.6664) tensor(-0.6182) tensor(-0.5406)\n",
      "tensor(-0.6029) tensor(-0.5671) tensor(-0.4936)\n",
      "tensor(-0.5395) tensor(-0.5137) tensor(-0.4453)\n",
      "tensor(-0.4760) tensor(-0.4582) tensor(-0.3957)\n",
      "tensor(-0.4125) tensor(-0.4009) tensor(-0.3451)\n",
      "tensor(-0.3491) tensor(-0.3420) tensor(-0.2936)\n",
      "tensor(-0.2856) tensor(-0.2817) tensor(-0.2412)\n",
      "tensor(-0.2221) tensor(-0.2203) tensor(-0.1883)\n",
      "tensor(-0.1587) tensor(-0.1580) tensor(-0.1348)\n",
      "tensor(1.00000e-02 *\n",
      "       -9.5200) tensor(1.00000e-02 *\n",
      "       -9.5056) tensor(1.00000e-02 *\n",
      "       -8.1051)\n",
      "tensor(1.00000e-02 *\n",
      "       -3.1733) tensor(1.00000e-02 *\n",
      "       -3.1728) tensor(1.00000e-02 *\n",
      "       -2.7041)\n",
      "tensor(1.00000e-02 *\n",
      "       3.1733) tensor(1.00000e-02 *\n",
      "       3.1728) tensor(1.00000e-02 *\n",
      "       2.7041)\n",
      "tensor(1.00000e-02 *\n",
      "       9.5200) tensor(1.00000e-02 *\n",
      "       9.5056) tensor(1.00000e-02 *\n",
      "       8.1051)\n",
      "tensor(0.1587) tensor(0.1580) tensor(0.1348)\n",
      "tensor(0.2221) tensor(0.2203) tensor(0.1883)\n",
      "tensor(0.2856) tensor(0.2817) tensor(0.2412)\n",
      "tensor(0.3491) tensor(0.3420) tensor(0.2936)\n",
      "tensor(0.4125) tensor(0.4009) tensor(0.3451)\n",
      "tensor(0.4760) tensor(0.4582) tensor(0.3957)\n",
      "tensor(0.5395) tensor(0.5137) tensor(0.4453)\n",
      "tensor(0.6029) tensor(0.5671) tensor(0.4936)\n",
      "tensor(0.6664) tensor(0.6182) tensor(0.5406)\n",
      "tensor(0.7299) tensor(0.6668) tensor(0.5861)\n",
      "tensor(0.7933) tensor(0.7127) tensor(0.6300)\n",
      "tensor(0.8568) tensor(0.7557) tensor(0.6721)\n",
      "tensor(0.9203) tensor(0.7958) tensor(0.7124)\n",
      "tensor(0.9837) tensor(0.8326) tensor(0.7505)\n",
      "tensor(1.0472) tensor(0.8660) tensor(0.7865)\n",
      "tensor(1.1107) tensor(0.8960) tensor(0.8201)\n",
      "tensor(1.1741) tensor(0.9224) tensor(0.8513)\n",
      "tensor(1.2376) tensor(0.9450) tensor(0.8798)\n",
      "tensor(1.3011) tensor(0.9638) tensor(0.9056)\n",
      "tensor(1.3645) tensor(0.9788) tensor(0.9285)\n",
      "tensor(1.4280) tensor(0.9898) tensor(0.9483)\n",
      "tensor(1.4915) tensor(0.9969) tensor(0.9649)\n",
      "tensor(1.5549) tensor(0.9999) tensor(0.9783)\n",
      "tensor(1.6184) tensor(0.9989) tensor(0.9881)\n",
      "tensor(1.6819) tensor(0.9938) tensor(0.9944)\n",
      "tensor(1.7453) tensor(0.9848) tensor(0.9968)\n",
      "tensor(1.8088) tensor(0.9718) tensor(0.9955)\n",
      "tensor(1.8723) tensor(0.9549) tensor(0.9900)\n",
      "tensor(1.9357) tensor(0.9341) tensor(0.9804)\n",
      "tensor(1.9992) tensor(0.9096) tensor(0.9665)\n",
      "tensor(2.0627) tensor(0.8815) tensor(0.9481)\n",
      "tensor(2.1261) tensor(0.8497) tensor(0.9251)\n",
      "tensor(2.1896) tensor(0.8146) tensor(0.8974)\n",
      "tensor(2.2531) tensor(0.7761) tensor(0.8648)\n",
      "tensor(2.3165) tensor(0.7346) tensor(0.8272)\n",
      "tensor(2.3800) tensor(0.6901) tensor(0.7844)\n",
      "tensor(2.4435) tensor(0.6428) tensor(0.7363)\n",
      "tensor(2.5069) tensor(0.5929) tensor(0.6827)\n",
      "tensor(2.5704) tensor(0.5406) tensor(0.6236)\n",
      "tensor(2.6339) tensor(0.4862) tensor(0.5587)\n",
      "tensor(2.6973) tensor(0.4298) tensor(0.4880)\n",
      "tensor(2.7608) tensor(0.3717) tensor(0.4112)\n",
      "tensor(2.8243) tensor(0.3120) tensor(0.3283)\n",
      "tensor(2.8877) tensor(0.2511) tensor(0.2391)\n",
      "tensor(2.9512) tensor(0.1893) tensor(0.1435)\n",
      "tensor(3.0147) tensor(0.1266) tensor(1.00000e-02 *\n",
      "       4.1222)\n",
      "tensor(3.0781) tensor(1.00000e-02 *\n",
      "       6.3424) tensor(1.00000e-02 *\n",
      "       -6.7733)\n",
      "tensor(3.1416) tensor(1.00000e-08 *\n",
      "       -8.7423) tensor(-0.1836)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fit_polynomial(D, x, y):\n",
    "    N = x.size(0)\n",
    "    X = torch.Tensor(N, D + 1)\n",
    "    for d in range(D + 1):\n",
    "        X[:,d] = x.pow(d)\n",
    "        \n",
    "    Y = y.view(N, 1)\n",
    "    alpha, _ = torch.gels(Y, X)\n",
    "    \n",
    "    return alpha.narrow(0,0,D+1)\n",
    "\n",
    "D, N = 4, 100\n",
    "x = torch.linspace(-math.pi, math.pi, N)\n",
    "y = x.sin()\n",
    "\n",
    "alpha = fit_polynomial(D, x, y)\n",
    "\n",
    "X = torch.Tensor(N, D + 1)\n",
    "for d in range(D + 1):\n",
    "    X[:,d] = x.pow(d)\n",
    "    \n",
    "z = X.mm(alpha).view(-1)\n",
    "\n",
    "for k in range(N):\n",
    "    print (x[k], y[k], z[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

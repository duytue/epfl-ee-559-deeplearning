{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim, cuda\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy loss\n",
    "* Compute the difference between two distributions\n",
    "* Compute how close predicted distribution to the true distribution\n",
    "* Usually used in **classification** problems\n",
    "* More info: https://stackoverflow.com/a/41990932\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0228)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.CrossEntropyLoss\n",
    "f = Variable(Tensor([[3, 3, -2], [1, -1, 2]]))\n",
    "target = Variable(LongTensor([0, 1]))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion(f, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LogSoftmax & NLLLoss\n",
    "* **Negative log likelihood loss** function: useful in **training** classification problem with C classes\n",
    "  * torch.nn.NLLLoss()\n",
    "* **Log soft-max** function: usually the final layer for a network **trained with NLLLoss()**\n",
    "  * torch.nn.LogSoftmax()\n",
    "* If a network should compute log probabilities, it may have a LogSoftmax() final layer, and be trained with NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Stochastic gradient descent\n",
    "* Update parameters w(t) after every sample (instead of every n samples for each iteration)\n",
    "* However, does not benefit from the speed-up of batch-processing\n",
    "* Hence, **mini-batch stochastic gradient descent** is used\n",
    "  * Visit samples in \"mini-batches\" (a few tens of samples), update parameters each mini-batch\n",
    "  * This behavior helps **evade local minima**\n",
    "* Example below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Momentum and moment estimation\n",
    "* Deep learning relies on smarter use of the gradient, using *statistics* over its past values to make a *smarter step* with the current one\n",
    "* The use of \"momentum\" to add *inertia* in the choice of step direction (see slide 5-P.22)\n",
    "  * With γ = 0, this is the same as normal Stochastic Gradient Descent (SGD)\n",
    "  * With γ > 0, advantages are:\n",
    "    * it can \"go through\" local barriers,\n",
    "    * it accelerates if gradient does not change much\n",
    "    * it dampends oscillations in narrow valleys.   \n",
    "    \n",
    "Vanilla SGD | With Momentum\n",
    "----- | -----\n",
    "![dampening1](img/lecture5/moment_dampening1.png) {width=75%} | ![dampening2](img/lecture5/moment_dampening2.png) {width=75%}\n",
    "   \n",
    "#### Adam Algorithm\n",
    "* Uses moving averages of each coordinate and its square to rescale each coordinate separately (see slide5-P.25)\n",
    "\n",
    "Vanilla SGD | Adam algorithm\n",
    "----- | -----\n",
    "![dampening1](img/lecture5/moment_dampening1.png) {width=75%} | ![adamalgo](img/lecture5/moment_adam.png) {width=75%}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal version is one used in pratical4\n",
    "# Stochastic Gradient Descent with torch.optim\n",
    "eta = 1e-1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = eta)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "\n",
    "for e in range(25):\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):\n",
    "        output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "        loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        # Stochastic and optim here, update after every batch size\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Putting things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(172.3186)\n",
      "1 tensor(36.4774)\n",
      "2 tensor(23.9906)\n",
      "3 tensor(17.9796)\n",
      "4 tensor(14.3676)\n",
      "5 tensor(11.5056)\n",
      "6 tensor(9.3696)\n",
      "7 tensor(7.4484)\n",
      "8 tensor(5.9644)\n",
      "9 tensor(4.7334)\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hiddens):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, nb_hiddens)\n",
    "        self.fc2 = nn.Linear(nb_hiddens, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "train_set = datasets.MNIST('./data/mnist/', train = True, download = True)\n",
    "train_input = Variable(train_set.train_data.view(-1, 1, 28, 28).float())\n",
    "train_target = Variable(train_set.train_labels)\n",
    "\n",
    "model, criterion = Net(200), nn.CrossEntropyLoss()\n",
    "\n",
    "if cuda.is_available():\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "    train_input, train_target = train_input.cuda(), train_target.cuda()\n",
    "    \n",
    "# normalization\n",
    "muy, std = train_input.data.mean(), train_input.data.std()\n",
    "train_input.data.sub_(muy).div_(std)\n",
    "\n",
    "lr, nb_epochs, batch_size = 1e-1, 10, 100\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "for k in range(nb_epochs):\n",
    "    sum_loss = 0\n",
    "    for b in range(0, train_input.size(0), batch_size):\n",
    "        output = model(train_input.narrow(0, b, batch_size))\n",
    "        loss = criterion(output, train_target.narrow(0, b, batch_size))\n",
    "        sum_loss += loss.data\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print (k, sum_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# REGULARIZATION\n",
    "\n",
    "Regularization is a process of modifying the model in order to prevent overfitting without changing its \"data core concept\" (idk :D).\n",
    "> Regularization, một cách cơ bản, là thay đổi mô hình một chút để tránh overfitting trong khi vẫn giữ được tính tổng quát của nó (tính tổng quát là tính mô tả được nhiều dữ liệu, trong cả tập training và test). Một cách cụ thể hơn, ta sẽ tìm cách **di chuyển nghiệm của bài toán tối ưu hàm mất mát tới một điểm gần nó**. Hướng di chuyển sẽ là hướng làm cho mô hình ít phức tạp hơn mặc dù giá trị của hàm mất mát có tăng lên một chút.   \n",
    "Reference: [machinelearningcoban.com](https://machinelearningcoban.com/2017/03/04/overfitting/#-regularization \"Regularization\")   \n",
    "\n",
    "Types of regularization:\n",
    "* Early stopping\n",
    "* L<sub>2</sub> regularization (weight decay): using norm 2 \n",
    "* L<sub>1</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Weight Initialization\n",
    "* Relies on controlling the variances (slide5-P.50) so that:\n",
    "  * the gradient does not vanish\n",
    "  * weights evolve at the same rate across layers during training and no layer reaches a saturation behavior before others\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance -> std = sqrt(Variance)   \n",
    "\n",
    "\n",
    "First Type | Xavier initialization\n",
    "--- | ---\n",
    "![weight1](img/lecture5/weight1.png) | ![xavier](img/lecture5/xavier.png)\n",
    "\n",
    "\n",
    "* This calculates the variance (or std) of variables like weights and biases so that we can later randomize them with it to get uniform gradients across all layers without them vanishing\n",
    "![betterweight](img/lecture5/graph1.png \"Before and after Xavier initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier implementation\n",
    "def xavier_init(tensor, gain = 1):\n",
    "    if isinstance(tensor, Variable):\n",
    "        xavier_normal(tensor.data, gain = gain)\n",
    "        return tensor\n",
    "    # N(l-1) & N(l)\n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n",
    "    # important\n",
    "    std = gain * math.sqrt(2.0 / (fan_in + fan_out))\n",
    "    return tensor.normal_(0, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ReLU impacts the forward and backward pass as if the weights had half their variances, which motivates multiplying them by a corrective gain of √2.\n",
    "*(He et al., 2015)*\n",
    "![Init coefficients](img/lecture5/init_coef.png \"Coefficients for each type of activation functions\")\n",
    "   \n",
    "Using these values in pratice:\n",
    "* For ReLU activation function: V = 2.0 / N(l-1)\n",
    "* For tanh activation function: V = 1.0 / N(l-1) (this is Xavier init)\n",
    "* V = 2.0 / (N(l-1) + N(l)): this is also Xavier init   \n",
    "[Reference: deeplearning.ai](https://www.coursera.org/learn/deep-neural-network/lecture/RwqYe/weight-initialization-for-deep-networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Normalization\n",
    "\n",
    "The analysis for the weight initialization relies on keeping the activation variance constant.   \n",
    "For this to be true, not only the variance has to remained unchanged through layers, but it has to be correct for the input too.   \n",
    "**V(x<sup>(0)</sup>) = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do as follow\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "# OR for component-wise normalization\n",
    "mu, std = train_input.mean(0), train_input.std(0)\n",
    "\n",
    "train_input.sub_(mu).div_(std)\n",
    "test_input.sub_(mu).div_(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Choosing the Network structure\n",
    "\n",
    "* Reuse or start from **\"well known, that works\"** structure\n",
    "* Split feature extraction / inference\n",
    "* Modulate the capacity until it overfits a small subset, but does not overfit/ underfit the full set\n",
    "* Capacity increases with more layers, more channels, larger receptive fields, or more units.\n",
    "* Regularization to reduce the capacity or induce sparsity.\n",
    "* Identify common paths for siamese-like ([For more info on Siamese network](https://www.quora.com/What-are-Siamese-neural-networks-what-applications-are-they-good-for-and-why \"Siamese network\")\n",
    "* Identify what path(s) or sub-parts need more/less capacity\n",
    "* Use prior knowledge about the \"scale of meaningful context\" to size filters/ combinations of filters (e.g. knowing the size of objects in a scene, the max duration of a sound snippet that matters).\n",
    "* Grid-search all the variations that come to mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on learning rate:\n",
    "* reduce the loss quickly -> large learning rate\n",
    "* not be trapped in a bad minimum -> large learning rate\n",
    "* not bounce around in narrow valleys -> small learning rate\n",
    "* not ascillate around a minimum -> small learning rate\n",
    "\n",
    "-> Using larger step size first, andn a smaller one in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
